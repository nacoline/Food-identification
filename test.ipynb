{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: pip in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (22.1.2)\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: albumentations in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (1.1.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from albumentations) (4.6.0.66)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: scipy in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from albumentations) (1.7.3)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from albumentations) (0.19.2)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from albumentations) (1.21.6)\n",
      "Requirement already satisfied: PyYAML in /home/ma-user/modelarts/modelarts-sdk (from albumentations) (6.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ma-user/modelarts/modelarts-sdk (from qudida>=0.0.4->albumentations) (4.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (9.1.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.19.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: timm in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (0.5.4)\n",
      "Requirement already satisfied: torch>=1.4 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from timm) (1.11.0)\n",
      "Requirement already satisfied: torchvision in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from timm) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ma-user/modelarts/modelarts-sdk (from torch>=1.4->timm) (4.0.1)\n",
      "Requirement already satisfied: numpy in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\n",
      "Requirement already satisfied: requests in /home/ma-user/modelarts/modelarts-sdk (from torchvision->timm) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from torchvision->timm) (9.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/modelarts/modelarts-sdk (from requests->torchvision->timm) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from requests->torchvision->timm) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ma-user/modelarts/modelarts-sdk (from requests->torchvision->timm) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ma-user/modelarts/modelarts-sdk (from requests->torchvision->timm) (2.0.12)\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: tqdm in /home/ma-user/modelarts/modelarts-sdk (4.62.3)\n"
     ]
    }
   ],
   "source": [
    "# 更新库\n",
    "! python -m pip install --upgrade pip\n",
    "! pip install -U albumentations\n",
    "! pip install timm\n",
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "#import moxing as mox \n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#mox.file.copy('obs://test-c3a5/food-11.zip', '/home/ma-user/work/food-11.zip') # 复制数据到当前路径\n",
    "#mox.file.copy('obs://test-c3a5/student_model.bin', '/home/ma-user/work/student_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解压\n",
    "!unzip food-11.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(path, label):\n",
    "    # label 是一個 boolean variable，代表需不需要回傳 y 值\n",
    "    image_dir = sorted(os.listdir(path))\n",
    "    x = np.zeros((len(image_dir), 128, 128, 3), dtype=np.uint8)\n",
    "    y = np.zeros((len(image_dir)), dtype=np.uint8)\n",
    "    for i, file in enumerate(image_dir):\n",
    "        img = cv2.imread(os.path.join(path, file))\n",
    "        x[i, :, :] = cv2.resize(img,(128, 128))\n",
    "        if label:\n",
    "          y[i] = int(file.split(\"_\")[0])\n",
    "    if label:\n",
    "      return x, y\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "Size of Testing data = 3347\n"
     ]
    }
   ],
   "source": [
    "workspace_dir = './food-11'\n",
    "#workspace_dir='E:\\\\2022\\\\Network_Compression\\\\food-11'\n",
    "print(\"Reading data\")\n",
    "test_x = readfile(os.path.join(workspace_dir, \"testing\"), False)\n",
    "print(\"Size of Testing data = {}\".format(len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                                    \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        # label is required to be a LongTensor\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentNet(nn.Module):\n",
    "    '''\n",
    "      在这个Net里面，我们会使用Depthwise & Pointwise Convolution Layer來叠model。\n",
    "      你会发現，将原本的Convolution Layer换成Dw & Pw以后，Accuracy通常不会降很多。\n",
    "\n",
    "      另外，取名为StudentNet是因為个odel等会要做Knowledge Distillation。\n",
    "    '''\n",
    "\n",
    "    def __init__(self, base=16, width_mult=1):\n",
    "        '''\n",
    "          Args:\n",
    "            base: 这个model一开始的channle数量，每过一层都会*2，直到base*16为止。\n",
    "            width_mult:为了之後的Network Pruning使用，在base*8 chs的Layer上会 * width_mult代表剪枝后的ch数量。        \n",
    "        '''\n",
    "        super(StudentNet, self).__init__()\n",
    "        multiplier = [1, 2, 4, 8, 16, 16, 18, 18]\n",
    "\n",
    "        # bandwidth: 每一层Layer所使用的ch數量\n",
    "        bandwidth = [ base * m for m in multiplier]\n",
    "\n",
    "        # 我们只Pruning第三层以后的Layer\n",
    "        for i in range(3, 7):\n",
    "            bandwidth[i] = int(bandwidth[i] * width_mult)\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            # 第一层我们通常不会拆解Convolution Layer。\n",
    "            # nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding)\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(3, bandwidth[0], 3, 1, 1),  # bandwidth[0]=1*16\n",
    "                nn.BatchNorm2d(bandwidth[0]),\n",
    "                nn.Hardswish(),\n",
    "                nn.MaxPool2d(2, 2, 0),\n",
    "            ),\n",
    "            # 接下来每一个Sequential Block都一样，所以我们只讲一个block\n",
    "            nn.Sequential(\n",
    "                # Depthwise Convolution 卷积层（x, x, x）\n",
    "                nn.Conv2d(bandwidth[0], bandwidth[0], 3, 1, 1, groups=bandwidth[0]),\n",
    "                # Batch Normalization\n",
    "                nn.BatchNorm2d(bandwidth[0]),\n",
    "                # 使用ReLU6的原因是因为如果数字太大，会不好压到float16 / or further qunatization，因此才給个限制。\n",
    "                nn.Hardswish(),\n",
    "                # Pointwise Convolution\n",
    "                nn.Conv2d(bandwidth[0], bandwidth[1], 1),\n",
    "                # 过完Pointwise Convolution不需要再做ReLU，经验上Pointwise + ReLU效果都会变差。\n",
    "                nn.MaxPool2d(2, 2, 0),\n",
    "                # 每过完一个Block就Down Sampling\n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[1], bandwidth[1], 3, 1, 1, groups=bandwidth[1]),\n",
    "                nn.BatchNorm2d(bandwidth[1]),\n",
    "                nn.Hardswish(),\n",
    "                nn.Conv2d(bandwidth[1], bandwidth[2], 1),\n",
    "                nn.MaxPool2d(2, 2, 0),\n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[2], bandwidth[2], 3, 1, 1, groups=bandwidth[2]),\n",
    "                nn.BatchNorm2d(bandwidth[2]),\n",
    "                nn.Hardswish(),\n",
    "                nn.Conv2d(bandwidth[2], bandwidth[3], 1),\n",
    "                nn.MaxPool2d(2, 2, 0),\n",
    "            ),\n",
    "\n",
    "            # 到这个为止是因为图片被Down Sample很多次了，所以就不做MaxPool\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[3], bandwidth[3], 3, 1, 1, groups=bandwidth[3]),\n",
    "                nn.BatchNorm2d(bandwidth[3]),\n",
    "                nn.Hardswish(),\n",
    "                nn.Conv2d(bandwidth[3], bandwidth[4], 1),\n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[4], bandwidth[4], 3, 1, 1, groups=bandwidth[4]),\n",
    "                nn.BatchNorm2d(bandwidth[4]),\n",
    "                nn.Hardswish(),\n",
    "                nn.Conv2d(bandwidth[4], bandwidth[5], 1),\n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[5], bandwidth[5], 3, 1, 1, groups=bandwidth[5]),\n",
    "                nn.BatchNorm2d(bandwidth[5]),\n",
    "                nn.Hardswish(),\n",
    "                nn.Conv2d(bandwidth[5], bandwidth[6], 1),\n",
    "            ),\n",
    "\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(bandwidth[6], bandwidth[6], 3, 1, 1, groups=bandwidth[6]),\n",
    "                nn.BatchNorm2d(bandwidth[6]),\n",
    "                nn.Hardswish(),\n",
    "                nn.Conv2d(bandwidth[6], bandwidth[7], 1),\n",
    "            ),\n",
    "\n",
    "            # 这边我们用Global Average Pooling。\n",
    "            # 如果输入图片大小不一样的话，就会因为Global Average Pooling压成一样的形狀，这样子接下来做FC就不会对不起来。\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            # 这边我们直接Project到11维输出答案。  数据集food种类为11\n",
    "            nn.Linear(bandwidth[7], 11),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_set = ImgDataset(test_x, transform=test_transform)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "student_net = StudentNet(base=16).cuda()\n",
    "\n",
    "student_net.load_state_dict(torch.load('student_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/105 [00:00<?, ?it/s]C:\\Users\\CAFE\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 105/105 [00:07<00:00, 14.20it/s]\n"
     ]
    }
   ],
   "source": [
    "student_net.eval()\n",
    "predictions = []\n",
    "for batch in tqdm(test_loader):\n",
    "    imgs = batch\n",
    "    with torch.no_grad():\n",
    "        logits = student_net(imgs.to(device))\n",
    "    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predict.csv\", 'w') as f:\n",
    "    f.write('Id,Category\\n')\n",
    "    for i, y in  enumerate(predictions):\n",
    "        f.write('{},{}\\n'.format(i, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moxing as mox \n",
    "# 修改为自己的桶目录\n",
    "mox.file.copy( '/home/ma-user/work/predict.csv','obs://test-c3a5/predict.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd2f4d87eb029ab8304423a0c27d1a3ab9869db7169c64a45424877fc0a465ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
